{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        ")\n",
        "import torch"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734103076285
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftModel,\n",
        "    TaskType,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734103087362
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -upgrade peft"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\r\nUsage:   \r\n  pip install [options] <requirement specifier> [package-index-options] ...\r\n  pip install [options] -r <requirements file> [package-index-options] ...\r\n  pip install [options] [-e] <vcs project url> ...\r\n  pip install [options] [-e] <local project path> ...\r\n  pip install [options] <archive url/path> ...\r\n\r\nno such option: -u\r\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model loading"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "HUG_MODEL = \"Preethi-1995/Llama-3-8B-Instruct-SQUAD\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(HUG_MODEL)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\n",
        "model = PeftModel.from_pretrained(model, HUG_MODEL)\n",
        "model = model.merge_and_unload() "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it]\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734105113100
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To upload the model to Azure blob storage**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-storage-blob"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import ContainerClient\n",
        "import os\n",
        "import yaml"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734096742150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files(dir):\n",
        "    with os.scandir(dir) as entries:\n",
        "        for entry in entries:\n",
        "            if entry.is_file() and not entry.name.startswith('.'):\n",
        "                yield entry"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734094441302
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/home/azureuser/cloudfiles/code/Users/EzhilKrishna/mnt/outputs/checkpoint-6160'\n",
        "files = get_files(dir)\n",
        "print(*files)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<DirEntry 'adapter_config.json'> <DirEntry 'adapter_model.safetensors'> <DirEntry 'optimizer.pt'> <DirEntry 'README.md'> <DirEntry 'rng_state.pth'> <DirEntry 'scheduler.pt'> <DirEntry 'special_tokens_map.json'> <DirEntry 'tokenizer.json'> <DirEntry 'tokenizer_config.json'> <DirEntry 'trainer_state.json'> <DirEntry 'training_args.bin'>\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734097277961
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_config():\n",
        "    dir_root = os.path.dirname(os.path.abspath(__file__))\n",
        "    with open(dir_root + '/config.yaml', 'r') as yamlfile:\n",
        "        return yaml.load(yamlfle, Loader=yaml.FullLoader)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload(files, connection_string, container_name):\n",
        "    container_client = ContainerClient.from_connection_string(connection_string, container_name)\n",
        "    print(\"Uplaoding files to blob storage...\")\n",
        "\n",
        "    for file in files:\n",
        "        print(file)\n",
        "        blob_client = container_client.get_blob_client(file.name)\n",
        "        with open(file.path, 'rb') as data:\n",
        "            blob_client.upload_blob(data)\n",
        "            print(f'{file.name} uploaded to blob storage')\n",
        "            os.remove(file)\n",
        "            print(f'{file.name} removed from')\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734097403872
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your Blob storage connection string\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=finetuningwork4299623425;AccountKey=csbb/r/kquzkPpuwf/nfIGw8GBnWUqGgFrPgLmp0YCNySmb9Rj4MCxRWNamz6j2c3a8DhGe+mwAF+AStpx1oHg==;EndpointSuffix=core.windows.net\"  # Replace with your storage account connection string\n",
        "#container_name = \"finetuningwork4299623425\" \n",
        "container_name = \"model-repo\" \n",
        "\n",
        "#upload(files, connection_string, container_name)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734097509886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient\n",
        "from azure.storage.blob import ContainerClient\n",
        "import os\n",
        "\n",
        "# Initialize the Blob Service Client\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "\n",
        "# Define the directory in ML Studio with files to upload\n",
        "local_directory = dir  # Replace with the ML Studio file path\n",
        "repository_name = 'squad_qa_f1_76'\n",
        "\n",
        "# Upload all files from the directory to the Blob container\n",
        "for root, dirs, files in os.walk(local_directory):\n",
        "    for file_name in files:\n",
        "        file_path = os.path.join(root, file_name)\n",
        "        relative_path = os.path.relpath(file_path, local_directory)\n",
        "        blob_name = f\"{repository_name}/{relative_path}\"\n",
        "        \n",
        "        # Create a Blob client\n",
        "        blob_client = container_client.get_blob_client(blob_name)\n",
        "        \n",
        "        # Upload file to Blob storage\n",
        "        with open(file_path, \"rb\") as data:\n",
        "            blob_client.upload_blob(data, overwrite=True)\n",
        "        \n",
        "        print(f\"Uploaded: {file_name} to {container_name}/{blob_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploaded: adapter_config.json to model-repo/squad_qa_f1_76/adapter_config.json\nUploaded: adapter_model.safetensors to model-repo/squad_qa_f1_76/adapter_model.safetensors\nUploaded: optimizer.pt to model-repo/squad_qa_f1_76/optimizer.pt\nUploaded: README.md to model-repo/squad_qa_f1_76/README.md\nUploaded: rng_state.pth to model-repo/squad_qa_f1_76/rng_state.pth\nUploaded: scheduler.pt to model-repo/squad_qa_f1_76/scheduler.pt\nUploaded: special_tokens_map.json to model-repo/squad_qa_f1_76/special_tokens_map.json\nUploaded: tokenizer.json to model-repo/squad_qa_f1_76/tokenizer.json\nUploaded: tokenizer_config.json to model-repo/squad_qa_f1_76/tokenizer_config.json\nUploaded: trainer_state.json to model-repo/squad_qa_f1_76/trainer_state.json\nUploaded: training_args.bin to model-repo/squad_qa_f1_76/training_args.bin\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734097732273
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}